{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPexp",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBDJzdz350B9XUvdvssgFD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ARSH7863/NLP/blob/master/NLPexp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Experiment 1  \n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "sample_text = \"I am Arsh Shaikh, and this is experiment one of NLP.\"\n",
        "tokens = word_tokenize(sample_text, language=\"english\")\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMFLe0T3PvQJ",
        "outputId": "23c07ba4-62fe-4f44-8371-5c31e289118f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "['I', 'am', 'Arsh', 'Shaikh', ',', 'and', 'this', 'is', 'experiment', 'one', 'of', 'NLP', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Experiment 2\n",
        "from polyglot.text import Text, Word\n",
        "# from polyglot.downloader import downloader\n",
        "# downloader.download(\"morph2.en\")\n",
        "words = [\"settlement\",\"carelessness\",\"almighty\"]\n",
        "for w in words:\n",
        "  w = Word(w, language=\"en\")\n",
        "  print(\"{:<20}{}\".format(w,w.morphemes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQuQZotCVZjH",
        "outputId": "018e348d-4d01-4e8d-9669-395653bddfae"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "settlement          ['settle', 'ment']\n",
            "carelessness        ['care', 'less', 'ness']\n",
            "almighty            ['al', 'mighty']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQSdCDOCLbwj",
        "outputId": "ef8238ff-732f-4e0b-8eb0-d9ab6444f6fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mutual fund investments',\n",
              " 'fund investments are',\n",
              " 'investments are subject',\n",
              " 'are subject to',\n",
              " 'subject to market',\n",
              " 'to market risks',\n",
              " 'market risks read',\n",
              " 'risks read whole',\n",
              " 'read whole scheme',\n",
              " 'whole scheme related',\n",
              " 'scheme related documents',\n",
              " 'related documents and',\n",
              " 'documents and invest',\n",
              " 'and invest carefully']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#Experiment 3\n",
        "import re\n",
        "\n",
        "s = \"Mutual fund investments are subject to market risks. Read whole scheme related documents and invest carefully.\"\n",
        "\n",
        "\n",
        "def generate_ngrams(s, n):\n",
        "    s = s.lower()\n",
        "    s = re.sub(r\"[^A-zA-Z0-9\\s]\", \"\", s)\n",
        "    token = [token for token in s.split(\" \") if token != \"\"]\n",
        "    ngrams = zip(*[token[i:] for i in range(n)])\n",
        "    return [\" \".join(ngram) for ngram in ngrams]\n",
        "\n",
        "\n",
        "generate_ngrams(s, n=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Experiment 4(1)\n",
        "from nltk import CFG\n",
        "from nltk.parse.generate import generate\n",
        "import nltk\n",
        "\n",
        "grammar1 = CFG.fromstring(\"\"\"\n",
        "S -> NP VP\n",
        "NP -> Det N\n",
        "NP -> Det ADJ N\n",
        "VP -> V\n",
        "VP -> V NP\n",
        "Det -> 'the'|'a'\n",
        "NP -> N\n",
        "N -> 'dogs'\n",
        "V -> 'cried'\n",
        "\"\"\")\n",
        "\n",
        "sentence = \"the dogs cried\".split()\n",
        "rd_parser = nltk.RecursiveDescentParser(grammar1)\n",
        "for tree in rd_parser.parse(sentence):\n",
        "  print(tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lhvu_g21QRh_",
        "outputId": "cdac77b5-fd75-4aec-a78a-9b54419ef755"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S (NP (Det the) (N dogs)) (VP (V cried)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kXLuLfuMONVl"
      }
    }
  ]
}